
Eva Borràs, Joan Ferré, Ricard Boqué, Montserrat Mestres, Laura Aceña, Olga Busto,
Data fusion methodologies for food and beverage authentication and quality assessment – A review,
Analytica Chimica Acta,
Volume 891,
2015,
Pages 1-14,
ISSN 0003-2670,
https://doi.org/10.1016/j.aca.2015.04.042.
(https://www.sciencedirect.com/science/article/pii/S0003267015005528)

**Abstract**: The ever increasing interest of consumers for safety, authenticity and quality of food commodities has driven the attention towards the analytical techniques used for analyzing these commodities. In recent years, rapid and reliable sensor, spectroscopic and chromatographic techniques have emerged that, together with multivariate and multiway chemometrics, have improved the whole control process by reducing the time of analysis and providing more informative results. In this progression of more and better information, the combination (fusion) of outputs of different instrumental techniques has emerged as a means for increasing the reliability of classification or prediction of foodstuff specifications as compared to using a single analytical technique. Although promising results have been obtained in food and beverage authentication and quality assessment, the combination of data from several techniques is not straightforward and represents an important challenge for chemometricians. This review provides a general overview of data fusion strategies that have been used in the field of food and beverage authentication and quality assessment.

Keywords: Data fusion; Chemometrics; Authentication; Food; Beverage; Classification

---

Usano le nostre stesse tecniche.

**IMPORTANTE**: aggiungono anche high-level data fusion
**SEZIONE 4.2**

In the low-level fusion data from all sources are simply concatenated sample-wise into a single matrix that has as many rows as samples analyzed and as many columns as signals (variables) measured by the different instruments. This is then used for calculating a single model that provides the final classification or prediction. Although concatenation can be done without additional mathematical preprocessing, specific operations may be necessary on the data from each source. Pre-processing methods, variable selection methods and feature extraction techniques are discussed in the sections below. Low-level fusion also includes the “outer product” of signal vectors [[38]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0190), [[82]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0410). All outputs of one instrument are multiplied by all outputs of another instrument, resulting in a three dimensional merged data matrix that consists of all possible combinations of the signal values from both instruments. The first dimension is equal to the number of samples, the second dimension represents the signals of the first instrument (variables) and the third dimension represents the signals of the other instrument (variables). This matrix can be analyzed with multiway methods or can be unfolded to two dimensions and analyzed with suitable multivariate methods.

Intermediate or mid-level fusion (also called feature level fusion) first [extracts](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/extract "Learn more about extracts from ScienceDirect's AI-generated Topic Pages") some relevant features from each data source separately and then concatenates them into a single array that is used for multivariate classification and regression ([Fig. 1](https://www.sciencedirect.com/science/article/pii/S0003267015005528#fig0005)). The most common approach is to fuse a number of latent variables obtained independently from the signals of each instrument. Usually scores from [principal component analysis](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/principal-component-analysis "Learn more about principal component analysis from ScienceDirect's AI-generated Topic Pages") (PCA) or partial-least squares [discriminant analysis](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/discriminant-analysis "Learn more about discriminant analysis from ScienceDirect's AI-generated Topic Pages") (PLS-DA) are used [[41]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0205). The challenge is to find the optimal combination of extracted features and pre-processing that describe the significant variation of the instrumental responses and provides the best final model.

In the high-level fusion, also called decision level fusion, separate classification or regression models are calculated from each data source, and the results from each individual model are combined to obtain the final identity declaration ([Fig. 1](https://www.sciencedirect.com/science/article/pii/S0003267015005528#fig0005)). The challenge in this case is to determine the classification or regression models that work best for each block so that their combination performs better than individual models. High-level data fusion in food analysis has mostly focused on classification problems. Bayesian inference based on probability estimation is the most used decision fusion technique [[90]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0450). For each source, an estimation of the probability that samples belong to a specific class is provided a priori and these preliminary identity declarations are combined to provide an updated joint probability for each possible entity. [Heuristic methods](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/heuristic-method "Learn more about Heuristic methods from ScienceDirect's AI-generated Topic Pages"), based on voting or scoring schemes, are also used. In voting schemes a democratic (weighted) process is addressed to fuse the identities; however, in scoring schemes a ranking of scores for each data source is specified for each candidate hypothesis [[90]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0450), [[91]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0455). Less used are the classical inferences, such as the Dempster–Shafer’s method [[92]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0460) and the generalized evidence processing (GEP) theory [[93]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0465). Classical inferences draw conclusions about an underlying distribution based on an observed sample of data, typically assuming an empirical probability model. Dempster–Shafer’s method and GEP theory, which are generalizations of the Bayesian techniques, have been applied to data with high level of uncertainty.

In summary, data fusion is mainly a data-driven approach. Low-level fusion is conceptually simple, uses a single model and can pick up correlations between variables of different blocks. Some limitations are a high data volume and the possible predominance of one data source over the others. This is partially overcome by mid-level fusion. Feature extraction significantly reduces the data dimensionality and allows each block to be treated individually. Also, mid-level is useful to filter block noise and enables interpretation of the results, since the contribution of each individual block can be visualized more easily than in low-level fusion. However, since many combinations of feature [extraction methods](https://www.sciencedirect.com/topics/chemistry/isolation-method "Learn more about extraction methods from ScienceDirect's AI-generated Topic Pages") and preprocessing are possible, testing all the combinations makes the whole process cumbersome, computationally intensive and difficult to validate. High-level fusion, on the other hand, allows focusing on the particularities of each individual technique, but the final identity declaration is obtained from only a few values that must accurately embed the main information from each technique. One advantage of this type of fusion is that every individual matrix is treated independently and the results from inefficient techniques do not worsen the overall performance as much as in the other fusion levels. However, this level requires accurate data preprocessing and if the correlation of the responses between sources is not taken into account information can be lost [[21]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0105), [[81]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0405). It must be noted that the nomenclature “low-level”, “mid-level” and “high-level” is sometimes used interchangeably in the literature and different denominations have been used. An example is coupled matrix and tensor factorization approach applied to the simultaneous analysis of two- and three-way matrices [[94]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0470). Even ‘hybrid’ data fusion methodologies, for example combining low- and mid-level approaches [[69]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0345), [[73]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0365). In this paper we adopted what seems to be the most accepted nomenclature.



----


**SPIEGA ANCHE PERCHé BISOGNA RISCALARE I DATI:**

Since [multivariate analysis](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/multivariate-analysis "Learn more about multivariate analysis from ScienceDirect's AI-generated Topic Pages") is scale dependent, data from single techniques are usually preprocessed in order to properly scale the data, and also remove uninformative systematic variations and reduce noise. Data from each source are treated specifically depending on their specific characteristics. For example, standard normal variate (SNV) was used for mid-infrared (MIR) data [[41]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0205), multiplicative scatter correction (MSC) was used for near- (NIR) and mid-infrared (MIR) spectra [[41]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0205), [[89]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0445) and derivatives were used to eliminate baseline shifts in [infrared spectra](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/infrared-spectra "Learn more about infrared spectra from ScienceDirect's AI-generated Topic Pages") [[39]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0195), [[42]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0210), [[47]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0235), baseline corrections and derivatives were used with UV–vis spectra [[39]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0195) scaling/normalization with mass spectra (MS) [[35]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0175), [[39]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0195), [[42]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0210), and misalignment peak correction with nuclear magnetic resonance (NMR) spectra [[50]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0250). In addition to the above, low-level data fusion may require additional preprocessing aimed to compensating for the different measuring scales and variability of each technique to prevent one block from being dominant [[95]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0475). In this sense each data block is weighted separately (block-scaling) usually with auto-scaling, root square scaling and log scaling. Finally, after data are merged, they are usually mean-centered before building the model. As in the case of low-level methodologies, extracted features in mid-level data fusion can also have different typology so scaling of the fused matrix can be required to build the model [[39]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0195), [[41]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0205), [[51]](https://www.sciencedirect.com/science/article/pii/S0003267015005528#bib0255).