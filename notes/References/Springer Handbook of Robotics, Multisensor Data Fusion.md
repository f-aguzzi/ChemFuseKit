
**Abstract:** Multisensor data fusion is the process of combining observations from a number of different sensors to provide a robust and complete description of an environment or process of interest. Data fusion finds wide application in many areas of robotics such as object recognition, environment mapping, and localization.

This chapter has three parts: methods, architectures, and applications. Most current data fusion methods employ probabilistic descriptions of observations and processes and use Bayes’ rule to combine this information. This chapter surveys the main probabilistic modeling and fusion techniques including grid-based models, Kalman filtering, and sequential Monte Carlo techniques. This chapter also briefly reviews a number of nonprobabilistic data fusion methods. Data fusion systems are often complex combinations of sensor devices, processing, and fusion algorithms. This chapter provides an overview of key principles in data fusion architectures from both a hardware and algorithmic viewpoint. The applications of data fusion are pervasive in robotics and underly the core problem of sensing, estimation, and perception. We highlight two example applications that bring out these features. The first describes a navigation or self-tracking application for an autonomous vehicle. The second describes an application in mapping and environment modeling.

The essential algorithmic tools of data fusion are reasonably well established. However, the development and use of these tools in realistic robotics applications is still developing.

### Cite this chapter

Durrant-Whyte, H., Henderson, T.C. (2016). Multisensor Data Fusion. In: Siciliano, B., Khatib, O. (eds) Springer Handbook of Robotics. Springer Handbooks. Springer, Cham. https://doi.org/10.1007/978-3-319-32552-1_35

### Download citation

- [.RIS](https://citation-needed.springer.com/v2/references/10.1007/978-3-319-32552-1_35?format=refman&flavour=citation "Download this article's citation as a .RIS file")
- [.ENW](https://citation-needed.springer.com/v2/references/10.1007/978-3-319-32552-1_35?format=endnote&flavour=citation "Download this article's citation as a .ENW file")
- [.BIB](https://citation-needed.springer.com/v2/references/10.1007/978-3-319-32552-1_35?format=bibtex&flavour=citation "Download this article's citation as a .BIB file")

- DOIhttps://doi.org/10.1007/978-3-319-32552-1_35
- Published27 July 2016
- Publisher NameSpringer, Cham
- Print ISBN978-3-319-32550-7
- Online ISBN978-3-319-32552-1
- eBook Packages[Engineering](https://link.springer.com/search?facet-content-type=%22Book%22&package=11647&facet-start-year=2016&facet-end-year=2016)[Engineering (R0)](https://link.springer.com/search?facet-content-type=%22Book%22&package=43712&facet-start-year=2016&facet-end-year=2016)

# Riassunto:

This chapter provides a comprehensive overview of data fusion methods in robotics, primarily focusing on those derived from statistics, estimation, and control. The most popular methods are probabilistic, based on Bayes' rule, which combines prior and observed information to make inferences about an object or environment.

Bayesian inference is a key part of these methods, requiring the relationship between the state and observation to be encoded as a joint probability. Bayes' rule is then used to update the prior probability with observed information, resulting in a posterior probability. Sensor models play a crucial role in this process, and multisensor Bayesian inference assumes conditional independence between sensors.

Bayesian filtering is a powerful technique for maintaining a probabilistic model for a state that evolves over time and is periodically observed. It forms the basis for many tracking and navigation problems in robotics. Probabilistic grids offer a simple way to implement Bayes' data fusion methods, applicable to mapping and tracking problems.

The Kalman filter is a widely used recursive linear estimator that calculates an estimate for a continuous state based on periodic observations. It is well-suited for tracking, localization, and navigation problems in robotics. The Extended Kalman Filter (EKF) and Information Filter are extensions of the Kalman filter, accommodating nonlinear models and multiple sensors, respectively.

^^ e questa è tutta roba per i sensori real time in serie storica

Sequential Monte Carlo (SMC) methods, also known as Monte Carlo filters, are another powerful tool for data fusion. They represent probability distributions as a set of weighted samples of an underlying state space, and these samples are used to simulate probabilistic inference through Bayes' rule.

Alternatives to probabilistic methods for representing uncertainty include interval calculus, fuzzy logic, and the theory of evidence (Dempster–Shafer methods). Each has its strengths and weaknesses, and their applicability depends on the specific requirements of the data fusion problem.

Multisensor fusion architectures can be organized in various ways, with one general framework consisting of meta-architecture, algorithmic architecture, conceptual architecture, logical architecture, and execution architecture. Examples of these architectures have been successfully applied to problems in robotics, such as dynamic system control and environment modeling.

In conclusion, multisensor data fusion has made significant advancements and is being applied in various fields, including robotics. Future research directions include developing a theoretical understanding of sensor system development, adaptivity, and learning, as well as creating a comprehensive framework for wireless sensor networks. The foundation for these developments is well-established, ensuring continued growth and innovation in the field.

^^ed è in questo spazio che si inseriscono BONAS e RISEN (wireless sensor networks).

---

The most popular data fusion methods in robotics are derived from statistics, estimation, and control, with a focus on autonomy. Probabilistic methods, based on Bayes' rule, are the standard approach. Bayes' rule combines prior and observation information to make inferences about an object or environment. Bayes' rule can be implemented through Kalman filters, sequential Monte Carlo methods, or functional density estimates. Alternatives to probabilistic methods, such as the theory of evidence and interval methods, exist but are less widely used.

Bayesian inference requires encoding the relationship between the state and observation as a joint probability. Bayes' rule is used to update the prior probability with observed information, resulting in a posterior probability. Sensor models play a crucial role in this process. Multisensor Bayesian inference assumes conditional independence between sensors.

Bayesian filtering is concerned with maintaining a probabilistic model for a state that evolves over time and is periodically observed. It forms the basis for many tracking and navigation problems. The general filtering problem can be formulated in Bayesian form, providing a common representation for various data fusion problems.

Probabilistic grids are a simple way to implement Bayes' data fusion methods, applicable to mapping and tracking problems. In mapping, the environment is divided into equally sized spatial cells, each labeled with a property. The focus is on maintaining a probability distribution of possible state values at each grid cell. For tracking and self-tracking, the state represents the location of the entity being tracked, with the probability distribution indicating the likelihood of the object occupying a grid cell. Bayes' rule is used to update probabilities based on observations.

The Kalman filter is a recursive linear estimator that calculates an estimate for a continuous state based on periodic observations. It employs statistical models for state evolution and observations, with gains chosen to minimize mean-squared error. The Kalman filter is well-suited for tracking, localization, and navigation problems in robotics. The Kalman filter is a specific instance of the recursive Bayesian filter for Gaussian state distributions. It defines a state-space model and an observation model, assuming Gaussian process and observation noises with known covariances. The Kalman filter produces estimates that minimize mean-squared estimation error. It proceeds in two stages: prediction and update. The prediction stage computes a prediction of the state and its covariance, while the update stage incorporates observations to compute an updated estimate.

The EKF handles nonlinear state and observation models. It linearizes the models using a Taylor series and follows the same prediction and update stages as the Kalman filter. The extended Kalman filter (EKF) is a nonlinear version of the Kalman filter, which linearizes the system around the current state estimate. The EKF update equations are similar to those of the Kalman filter, with the substitution of the Jacobian matrices for the state transition and observation matrices. The EKF has some caveats, such as the need for accurate initialization, the potential for instability if the linearization is not close enough to the true state, and the increased computational complexity due to the calculation of Jacobians.

The information filter is an alternative form of the Kalman filter that works with information state variables and matrices instead of state estimates and covariances. The information filter has a duality with the Kalman filter and offers a simpler update stage for data fusion problems with multiple sensors. However, it may be more difficult to implement for nonlinear systems, especially in the prediction step.

In summary, Kalman or information filters are suitable for data fusion problems with continuous parametric states, such as position, attitude, and velocity estimation, or tracking simple geometric features. They are not appropriate for estimating properties like spatial occupancy, discrete labels, or processes with hard-to-parameterize error characteristics.

Sequential Monte Carlo (SMC) methods, also known as Monte Carlo filters, represent probability distributions as a set of weighted samples of an underlying state space. These samples are used to simulate probabilistic inference through Bayes' rule. In SMC methods, probability distributions are described using support points and corresponding normalized weights. The support points and weights are selected using an importance density. The weights are computed based on the ratio of the probability densities of the support point and the importance density. SMC filtering simulates the recursive Bayes update equations using sample support values and weights to describe the underlying probability distributions. The algorithm consists of a prediction step, where new support values are drawn based on old support values, and an observation update step, where the weights are updated based on the likelihood of the observation. Resampling is performed to focus the samples on areas with the highest probability density. The decision to resample is based on the effective number of particles in the sample. Resampling can cause sample impoverishment, where the sample set fixates on a few highly likely samples. Monte Carlo methods are suitable for problems with highly nonlinear state-transition and observation models, as they can represent very general probability densities, including multimodal or multiple hypothesis density functions. However, they are less appropriate for problems with high-dimensional state spaces, as the number of samples required to faithfully model a given density increases exponentially with state-space dimension.

There are three main alternatives to probabilistic methods for representing uncertainty: interval calculus, fuzzy logic, and the theory of evidence (Dempster–Shafer methods).
Interval calculus represents uncertainty using an interval to bound true parameter values. It is useful when there is a lack of probabilistic information but sensor and parameter error is known to be bounded. However, interval calculus is not generally used in data fusion problems due to difficulties in achieving convergence and encoding dependencies between variables.
Fuzzy logic represents uncertainty using degrees of membership in fuzzy sets, ranging between 0 and 1. It has found widespread popularity in applications such as supervisory control and high-level data fusion tasks. Fuzzy logic provides a systematic means of reasoning about inexact values. Evidential reasoning, or the Dempster–Shafer theory of evidence, allows belief mass to be placed on elements, sets, and sets of sets. This method captures ignorance or an inability to distinguish between alternatives, providing a richer representation of beliefs than probability theory. However, its complexity increases substantially with the number of elements in the set, making it challenging for continuous or large sets. Evidential reasoning can be useful in discrete data fusion systems, particularly in areas such as attribute fusion and situation assessment.

Multisensor fusion architectures can be organized in various ways, with one general framework consisting of meta-architecture, algorithmic architecture, conceptual architecture, logical architecture, and execution architecture. Centralized, local interaction, and hierarchical architectures are one type of multisensor fusion architecture, which encompasses several system philosophies, including subsumption architecture, distributed field robot architecture (DFRA), and artificial neural networks. Other approaches to sensor fusion include task-oriented methods and methodologies based on model selection and representation size.
Decentralized multisensor fusion architectures can be classified into three types: global interaction and heterarchical, local interaction and hierarchical, and local interaction and heterarchical. The blackboard system is a major example of the global interaction and heterarchical architecture, where modular agents post results to a blackboard and collaborate efficiently in a dynamic configuration. The active sensor network (ASN) framework is an example of the local interaction and heterarchical architecture, which is decentralized, modular, and scalable with peer-to-peer communication. ASN consists of belief fusion, utility fusion, and policy selection algorithms, and its logical architecture is comprised of six canonical component types.

  
Multisensor fusion systems have been applied to various problems in robotics, with dynamic system control and environment modeling being two primary areas. The EMS-Vision system is an example of dynamic system control, using inertial and vision sensors to produce a road scene tree and a 4-D generic object representation for autonomous vehicles. The ANSER II project is an example of decentralized data fusion, which generalizes the DDF method for non-Gaussian probabilities and incorporates information from various sources, such as air and ground vehicles, terrain databases, and human operatives. Recent developments in multisensor fusion methods have been made in theory, vision, biomedical applications, tracking, terrain classification, and robotics and automation.

In conclusion, multisensor data fusion has made significant advancements and is being applied in various fields, including robotics, large-scale sensor systems, bio-based or biomimetic systems, medical in situ applications, and wireless sensor networks. Future research directions include developing a theoretical understanding of sensor system development, adaptivity, and learning, as well as creating a comprehensive framework for wireless sensor networks. The unification of numerical analysis of algorithmic properties with sensor data error sources is also an important area of research. The foundation for these developments is well-established, ensuring continued growth and innovation in the field.