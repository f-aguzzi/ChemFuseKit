{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example script\n",
    "\n",
    "This simple Jupyter Notebook will exemplify a simple workflow using this library, starting from data fusion and ending with prediction.\n",
    "\n",
    "## Step zero: install the library (and get the example data)\n",
    "Let's install the package from `PyPI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chemfusekit\n",
    "\n",
    "# Optional: download the example data from the repository (you could upload your own files)\n",
    "!wget https://github.com/f-aguzzi/tesi/raw/main/tests/qepas.xlsx\n",
    "!wget https://github.com/f-aguzzi/tesi/raw/main/tests/rt.xlsx\n",
    "\n",
    "# Automatically inline the graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: Low-Level Data Fusion\n",
    "- the `LLDF` class is used for data fusion\n",
    "- the `LLDF_Settings` class is a helper class for setting up `LLDF`\n",
    "- `LLDF` data can then be exported, or used for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from chemfusekit.lldf import LLDFSettings, LLDF\n",
    "\n",
    "# Initialize the settings for low-level data fusion\n",
    "lldf_settings = LLDFSettings(\n",
    "    qepas_path='tests/qepas.xlsx',    # (or put the name of your files)\n",
    "    qepas_sheet='Sheet1',\n",
    "    rt_path='tests/rt.xlsx',\n",
    "    rt_sheet='Sheet1',\n",
    "    preprocessing='snv'  # normalization preprocessing; other options: savgol or both\n",
    ")\n",
    "\n",
    "# Initialize and run low-level data fusion\n",
    "lldf = LLDF(lldf_settings)\n",
    "lldf.lldf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) export the LLDF data to an Excel file\n",
    "lldf.export_data('output_file.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step: PCA\n",
    "\n",
    "The `PCA` class provides Principal Component Analysis tools. Given:\n",
    "- a target variance level to maintain even in the reduced component model;\n",
    "- a confidence level for statistical tests;\n",
    "- a number of initial components for the analysis\n",
    "through the `PCASettings` class, the `PCA` class will perform an automated PCA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemfusekit.pca import PCASettings, PCA, GraphMode\n",
    "\n",
    "# Initialize the settings for Principal Component Analysis\n",
    "pca_settings = PCASettings(\n",
    "    target_variance=0.99,\n",
    "    confidence_level=0.05,\n",
    "    initial_components=10,\n",
    "    output=GraphMode.GRAPHIC # graphs will be printed as pictures\n",
    ")\n",
    "\n",
    "# Initialize and run the PCA class\n",
    "pca = PCA(lldf.fused_data, pca_settings)\n",
    "pca.pca()\n",
    "\n",
    "# Print the number of components and the statistics\n",
    "print(f\"\\nNumber of components: {pca.components}\\n\")\n",
    "pca.pca_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step: LDA training\n",
    "\n",
    "- the `LDA` class provides Linear Discriminant Analysis tools\n",
    "- the `LDASettings` helper class holds the settings for the `LDA` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemfusekit.lda import LDASettings, LDA, GraphMode\n",
    "\n",
    "settings = LDASettings(\n",
    "    components=(pca.components - 1),    # one less component than the number determined by PCA\n",
    "    output=GraphMode.GRAPHIC,   # graphs will be printed as pictures\n",
    "    test_split=True # Run split test\n",
    ")\n",
    "\n",
    "# Initialize and run the LDA class\n",
    "lda = LDA(lldf.fused_data, settings)\n",
    "lda.lda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: LDA prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a random sample and see if it gets recognized correctly:\n",
    "x_data_sample = lldf.fused_data.x_train.iloc[119] # should be DMMP\n",
    "x_data_sample = x_data_sample.iloc[1:].to_frame().transpose()\n",
    "\n",
    "# Let's run the prediction:\n",
    "predictions = lda.predict(x_data_sample)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adf20f4cd3c09df9458869b76345de81eb21527fdd82bbecfd21ff585123f63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
