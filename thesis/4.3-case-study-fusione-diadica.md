## Case study 3: fusione di dati tramite prodotto matriciale diadico

### Introduzione

### Metodologia

I dati utilizzati in questo esempio sono gli stessi dello studio di caso precedente. Contengono due tabelle, una di rilevazioni effettuate con un sensore QEPAS, e l’altra con rilevazioni di un sensore GC. Ogni tabella contiene 446 campioni di 17 possibili sostanze diverse. I dati del sensore QEPAS sono vettori a 128 componenti, e rappresentano la risposta spettrale dei campioni nelle bande tra gli 8 nm e i 10 nm. I dati del sensore QEPAS sono vettori a 128 componenti, e rappresentano la risposta spettrale dei campioni nelle bande tra gli 8 nm e i 10 nm. I dati del sensore GC constano di un valore scalare per ogni campione, il quale rappresenta il tempo di ritenzione del campione gassoso all’interno del sensore. I dati spettrografici del sensore QEPAS necessitano di preprocessamento via normalizzazione SNV. Nella prima fase dell’analisi, i dati vengono fusi a basso livello, ovvero senza estrazione preliminare delle caratteristiche. Nella seconda fase, un passaggio di selezione delle caratteristiche viene anteposta alla fusione, in un approccio a medio livello. Per entrambe le fasi, ogni operazione di fusione è ripetuta sia nella variante concatenatoria che in quella diadica.

Si confrontino ora i due approcci di fusione. Il metodo più semplice e intuitivo per unire i dati provenienti da due diversi sensori è concatenarli riga per riga. Ogni sensore produce una tabella dove ogni riga rappresenta un campione e ogni colonna è una componente di tale campione. Possiamo concatenare lateralmente tabelle provenienti da diversi sensori, se il numero di campioni è lo stesso e ogni riga si riferisce alla stessa rilevazione. Otteniamo una tabella fusa contenente lo stesso numero di campioni delle tabelle originali. Il numero delle sue colonne è pari alla somma di tutte le componenti di tutti i sensori dei quali stiamo fondendo i dati. Questa tecnica è utilizzata da quasi tutti gli studi considerati. Il suo difetto principale è l’eccessivo aumento di dimensionalità. Come spiegato nello studio di caso riguardante la fusione a medio livello, questo fenomeno può causare un aumento del rumore senza apportare vero segnale. Il secondo difetto è la predominanza dei sensori ad alta dimensionalità sui sensori a bassa dimensionalità. Un documento di ricerca sull’analisi delle pesce (Di Natale et al.) propone una tecnica alternativa alla concatenazione, basata sul prodotto diadico tra matrici, che risolve parzialmente questi problemi.

```mermaid
flowchart TD
    accTitle: Confronto tra metodi di fusione
    accDescr: Il metodo di fusione per concatenazione (sinistra) confrontato con il metodo di fusione per prodotto diadico (destra).
    
    subgraph Fusione per prodotto diadico
    T21[Tabella 1\nm ⨯ l] --> P1((Prodotto diadico\nm ⨯ l ⨯ n))
    T22[Tabella 2\nn ⨯ l] --> P1
    P1 -- Somma lungo l'asse verticale --> C2[Tabella parziale 1\nm ⨯ l]
    C2 --> P2((Prodotto diadico\nm ⨯ l ⨯ p))
    T23[Tabella 3\np ⨯ l] --> P2
    P2 -- Somma lungo l'asse verticale --> C3[Tabella finale \nm ⨯ l]
    end

    subgraph Fusione per concatenazione
    T11[Tabella 1\nm ⨯ l] --> C1((Concatenazione))
    T12[Tabella 2\nn ⨯ l] --> C1
    T13[Tabella 3\np ⨯ l] --> C1
    C1 --> T1F["Tabella finale\n(m + n + p) ⨯ l"]
    end
```

Il prodotto diadico tra matrici può essere visualizzato come operazione tridimensionale. Le due matrici da moltiplicare sono poste come facce contigue di un parallelepipedo. La lunghezza dello spigolo in comune rappresenta il numero di campioni nelle due tabelle. Il valore di ogni cella tridimensionale nel parallelepipedo corrisponde al prodotto dei valori delle celle bidimensionali che sono sue proiezioni sui lati lungo gli assi verticali e orizzontali. In altre parole, all’incrocio delle normali di due celle dei lati contenenti le matrici, si trova una cella tridimensionale il cui valore è il prodotto delle due celle bidimensionali. Il risultato dell’operazione è dunque una matrice tridimensionale, che ha per larghezza l’ampiezza della prima matrice, per lunghezza il numero di campioni di entrambe, e per altezza l’ampiezza della seconda matrice. Alcuni metodi di regressione, come ad esempio PLSDA, sono in grado di interpretare dati bidimensionali. Di conseguenza, sezioni bidimensionali della matrice possono essere usate come campioni. Alternativamente, la matrice tridimensionale può essere collassata a matrice bidimensionale, sommando i suoi valori lungo un asse. Nel caso di questo progetto, sommiamo sempre lungo le colonne verticali, per ottenere una matrice che abbia le stesse dimensioni della prima matrice operanda. Il vantaggio di questo approccio basato sul prodotto diadico è che i valori della tabella fusa rappresentano una sorta di media pesata tra i sensori.


### Risultati

Analizziamo in questo paragrafo i risultati dell'esperimento basato sulla regressione logistica *one versus rest*. Il classificatore che utilizza dati fusi a basso livello per concatenazione ottiene un punteggio identico a quello che utilizza i soli dati del sensore QEPAS. Potrebbe trattarsi di un esempio della problematica di diluizione dei dati presentata in letteratura. Al contrario, la fusione a basso livello basata sul prodotto diadico produce un significativo miglioramento rispetto al solo QEPAS, producendo un ottimo classificatore. L'algoritmo di regressione logistica multivariata sembra in grado di gestire aproblematicamente un ampio numero di regressori. Conseguentemente, ogni operazione di selezione delle caratteristiche tende a produrre modelli meno efficaci rispetto all'utilizzo di dati non ridotti. Tenendo in mente questa considerazione, affrontiamo di seguito i casi in cui venga utilizzata l'estrazione delle caratteristiche. Non inaspettatamente, il modello addestrato sulle caratteristiche estratte dai soli dati QEPAS è sensibilmente peggiore rispetto alla versione addestrata sui dati grezzi. Si analizzi ora il penultimo caso, ovvero l'estrazione delle caratteristiche come passaggio successivo alla fusione a basso livello. Il modello addestrato sulle caratteristiche estratte dai dati fusi per concatenazione è peggiore rispetto al modello basato sulle caratteristiche estratte dai soli dati QEPAS. Il modello con la qualità massima, tra quelli basati sull'estrazione delle caratteristiche, è addestrato sulle variabili estratte dai dati fusi a basso livello per prodotto diadico. Il risultato è significativamente migliore sia del modello addestrato sulle caratteristiche di QEPAS, che del modello addestrato sulle caratteristiche dei dati fusi a basso livello per concatenazione. Nel caso finale si applica la fusione a medio livello. In questo frangente, il modello ottenuto dai dati fusi per prodotto diadico risulta superiore rispetto al modello ottenuto per concatenazione, ma peggiore rispetto al suo equivalente ottenuto dalle caratteristiche estratte dai dati fusi a basso livello. Il modello ottenuto per concatenazione nella fusione a medio livello risulta invece migliore del suo equivalente ottenuto dall'estrazione delle caratteristiche post-fusione a basso livello.

Consideriamo ora i risultati relativi alla classificazione k-Nearest Neighbors. I modelli addestrati sui dati fusi producono una classificazione migliore rispetto al modello addestrato sui soli dati QEPAS, per entrambe le tecniche di fusione a basso livello, ovvero concatenazione e prodotto diadico. Tenuto questo in considerazione, il modello addestrato sui dati concatenati si dimostra superiore rispetto al modello addestrato sui dati moltiplicati diadicamente. Si consideri ora il gruppo di analisi con procedure di estrazione delle caratteristiche. Il modello addestrato sulle caratteristiche estratte dai dati QEPAS è leggermente peggiore, ma non significativamente, rispetto al corrispettivo addestato sui dati grezzi. Anche in questo frangente i risultati dell’addestramento su dati fusi a basso livello si rivelano migliori rispetto all’addestramento sui soli dati QEPAS. Si mantiene il primato dei risultati ottenuti dai dati concatenati rispetto ai dati fusi per prodotto diadico. Entrambi i risultati sono leggermente peggiori rispetto ai casi equivalenti senza fusione, in linea con quanto osservato per i modelli basati sui soli dati QEPAS. La categoria che presenta i risultati complessivamente migliori risulta essere quella basata sulla fusione a medio livello. Anche in quest’ultimo versante l’approccio per concatenazione vince sull’approccio per prodotto diadico. Il risultato di quest’ultimo è però comparabile a quello del modello addestrato sulle caratteristiche dei dati fusi per concatenazione, affrontato nel caso precedente. I punteggi del modello addestrato sui dati concatenati si rivelano invece comparabili ai risutlati del modello ottenuto per fusione a basso livello nel caso equivalente. Si può affermare che la fusione a medio livello sia l’approccio più sicuro per preparare i dati alla classificazione kNN, perché essa produce risultati equivalenti o migliori rispetto ai risultati di tutti gli altri casi.

Si consideri infine il caso con classificazione LDA. In esso, i risultati cambiano significativamente a seconda del metodo utilizzato per decidere il numero di componenti. L’algoritmo LDA prevede un passaggio di estrazione delle caratteristiche. Esso non possiede capacità intrinseche per la scelta del numero di caratteristiche da estrarre. Di conseguenza, questa scelta deve essere affidata ad un algoritmo esterno. Uno dei metodi possibili per la scelta del numero di componenti è la validazione incrociata a cinque pieghe. Quando applicata ai dati di questo esempio, essa produce un classificatore LDA monocomponente. Tutte le varianti del modello, ad eccezione di quella addestrata sui dati fusi per concatenazione a basso livello, risultano significativamente peggiori rispetto al modello ottenuto dai soli dati QEPAS. L’applicazione della riduzione di dimensionalità in seguito alla fusione a basso livello produce risultati equivalenti tra la variante concatenata e la variante diadica. Nel caso della fusione a medio livello l’approccio migliore è invece quello di fusione per prodotto diadico, con una differenza significativa rispetto alla fusione per concatenazione. Per la scelta del numero di componenti, un metodo alternativo alla validazione incrociata è l’analisi PCA. Utilizzando questo secondo approccio, tutti i modelli ottenuti si dimostrano inferiori al classificatore addestrato sui dati QEPAS non ridimensionati. Quest’ultimo raggiunge infatti risultati perfetti, classificando correttamente tutti i campioni dell’insieme di validazione. La fusione a basso livello produce risultati equivalenti con entrambe le tecniche di concatenazione e prodotto diadico. Lo stesso avviene per l’approccio a medio livello, che tuttavia risulta complessivamente il caso peggiore tra quelli considerati. Tra i modelli addestrati su dati ridimensionati, il migliore è ottenuto dalla fusione diadica a basso livello seguita dall’estrazione delle caratteristiche.


### Discussione

### Conclusioni

