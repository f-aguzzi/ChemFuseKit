## Case study 3: fusione di dati tramite prodotto matriciale diadico

### Introduzione

### Metodologia

```mermaid
flowchart TD
    accTitle: Confronto tra metodi di fusione
    accDescr: Il metodo di fusione per concatenazione (sinistra) confrontato con il metodo di fusione per prodotto diadico (destra).
    
    subgraph Fusione per prodotto diadico
    T21[Tabella 1\nm ⨯ l] --> P1((Prodotto diadico\nm ⨯ l ⨯ n))
    T22[Tabella 2\nn ⨯ l] --> P1
    P1 -- Somma lungo l'asse verticale --> C2[Tabella parziale 1\nm ⨯ l]
    C2 --> P2((Prodotto diadico\nm ⨯ l ⨯ p))
    T23[Tabella 3\np ⨯ l] --> P2
    P2 -- Somma lungo l'asse verticale --> C3[Tabella finale \nm ⨯ l]
    end

    subgraph Fusione per concatenazione
    T11[Tabella 1\nm ⨯ l] --> C1((Concatenazione))
    T12[Tabella 2\nn ⨯ l] --> C1
    T13[Tabella 3\np ⨯ l] --> C1
    C1 --> T1F["Tabella finale\n(m + n + p) ⨯ l"]
    end
```

### Risultati

Analizziamo in questo paragrafo i risultati dell'esperimento basato sulla regressione logistica *one versus rest*. Il classificatore che utilizza dati fusi a basso livello per concatenazione ottiene un punteggio identico a quello che utilizza i soli dati del sensore QEPAS. Potrebbe trattarsi di un esempio della problematica di diluizione dei dati presentata in letteratura. Al contrario, la fusione a basso livello basata sul prodotto diadico produce un significativo miglioramento rispetto al solo QEPAS, producendo un ottimo classificatore. L'algoritmo di regressione logistica multivariata sembra in grado di gestire aproblematicamente un ampio numero di regressori. Conseguentemente, ogni operazione di selezione delle caratteristiche tende a produrre modelli meno efficaci rispetto all'utilizzo di dati non ridotti. Tenendo in mente questa considerazione, affrontiamo di seguito i casi in cui venga utilizzata l'estrazione delle caratteristiche. Non inaspettatamente, il modello addestrato sulle caratteristiche estratte dai soli dati QEPAS è sensibilmente peggiore rispetto alla versione addestrata sui dati grezzi. Si analizzi ora il penultimo caso, ovvero l'estrazione delle caratteristiche come passaggio successivo alla fusione a basso livello. Il modello addestrato sulle caratteristiche estratte dai dati fusi per concatenazione è peggiore rispetto al modello basato sulle caratteristiche estratte dai soli dati QEPAS. Il modello con la qualità massima, tra quelli basati sull'estrazione delle caratteristiche, è addestrato sulle variabili estratte dai dati fusi a basso livello per prodotto diadico. Il risultato è significativamente migliore sia del modello addestrato sulle caratteristiche di QEPAS, che del modello addestrato sulle caratteristiche dei dati fusi a basso livello per concatenazione. Nel caso finale si applica la fusione a medio livello. In questo frangente, il modello ottenuto dai dati fusi per prodotto diadico risulta superiore rispetto al modello ottenuto per concatenazione, ma peggiore rispetto al suo equivalente ottenuto dalle caratteristiche estratte dai dati fusi a basso livello. Il modello ottenuto per concatenazione nella fusione a medio livello risulta invece migliore del suo equivalente ottenuto dall'estrazione delle caratteristiche post-fusione a basso livello.

Consideriamo ora i risultati relativi alla classificazione k-Nearest Neighbors. I modelli addestrati sui dati fusi producono una classificazione migliore rispetto al modello addestrato sui soli dati QEPAS, per entrambe le tecniche di fusione a basso livello, ovvero concatenazione e prodotto diadico. Tenuto questo in considerazione, il modello addestrato sui dati concatenati si dimostra superiore rispetto al modello addestrato sui dati moltiplicati diadicamente. Si consideri ora il gruppo di analisi con procedure di estrazione delle caratteristiche. Il modello addestrato sulle caratteristiche estratte dai dati QEPAS è leggermente peggiore, ma non significativamente, rispetto al corrispettivo addestato sui dati grezzi. Anche in questo frangente i risultati dell’addestramento su dati fusi a basso livello si rivelano migliori rispetto all’addestramento sui soli dati QEPAS. Si mantiene il primato dei risultati ottenuti dai dati concatenati rispetto ai dati fusi per prodotto diadico. Entrambi i risultati sono leggermente peggiori rispetto ai casi equivalenti senza fusione, in linea con quanto osservato per i modelli basati sui soli dati QEPAS. La categoria che presenta i risultati complessivamente migliori risulta essere quella basata sulla fusione a medio livello. Anche in quest’ultimo versante l’approccio per concatenazione vince sull’approccio per prodotto diadico. Il risultato di quest’ultimo è però comparabile a quello del modello addestrato sulle caratteristiche dei dati fusi per concatenazione, affrontato nel caso precedente. I punteggi del modello addestrato sui dati concatenati si rivelano invece comparabili ai risutlati del modello ottenuto per fusione a basso livello nel caso equivalente. Si può affermare che la fusione a medio livello sia l’approccio più sicuro per preparare i dati alla classificazione kNN, perché essa produce risultati equivalenti o migliori rispetto ai risultati di tutti gli altri casi.

Si consideri infine il caso con classificazione LDA. In esso, i risultati cambiano significativamente a seconda del metodo utilizzato per decidere il numero di componenti. L’algoritmo LDA prevede un passaggio di estrazione delle caratteristiche. Esso non possiede capacità intrinseche per la scelta del numero di caratteristiche da estrarre. Di conseguenza, questa scelta deve essere affidata ad un algoritmo esterno. Uno dei metodi possibili per la scelta del numero di componenti è la validazione incrociata a cinque pieghe. Quando applicata ai dati di questo esempio, essa produce un classificatore LDA monocomponente. Tutte le varianti del modello, ad eccezione di quella addestrata sui dati fusi per concatenazione a basso livello, risultano significativamente peggiori rispetto al modello ottenuto dai soli dati QEPAS. L’applicazione della riduzione di dimensionalità in seguito alla fusione a basso livello produce risultati equivalenti tra la variante concatenata e la variante diadica. Nel caso della fusione a medio livello l’approccio migliore è invece quello di fusione per prodotto diadico, con una differenza significativa rispetto alla fusione per concatenazione. Per la scelta del numero di componenti, un metodo alternativo alla validazione incrociata è l’analisi PCA. Utilizzando questo secondo approccio, tutti i modelli ottenuti si dimostrano inferiori al classificatore addestrato sui dati QEPAS non ridimensionati. Quest’ultimo raggiunge infatti risultati perfetti, classificando correttamente tutti i campioni dell’insieme di validazione. La fusione a basso livello produce risultati equivalenti con entrambe le tecniche di concatenazione e prodotto diadico. Lo stesso avviene per l’approccio a medio livello, che tuttavia risulta complessivamente il caso peggiore tra quelli considerati. Tra i modelli addestrati su dati ridimensionati, il migliore è ottenuto dalla fusione diadica a basso livello seguita dall’estrazione delle caratteristiche.


### Discussione

### Conclusioni

